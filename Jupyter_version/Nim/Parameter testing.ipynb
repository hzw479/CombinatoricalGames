{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccafc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1dbcdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01 #alpha\n",
    "decay_gamma=0.7 #gamma\n",
    "exp_rate=0.3 #epsilon\n",
    "starting_player='agent'\n",
    "list_of_winners=[]\n",
    "policy={}\n",
    "initial_board=[3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91e79fe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NimGame:\n",
    "    def __init__(self, init_board):\n",
    "        self.board=initial_board.copy()\n",
    "        self.number_of_piles=np.count_nonzero(self.board)\n",
    "        self.player=starting_player\n",
    "        self.winner=None\n",
    "        self.starting_player=starting_player\n",
    "        self.states_value={}\n",
    "        self.states=[]\n",
    "        self.exp_rate=exp_rate\n",
    "        self.lr=learning_rate\n",
    "        self.gamma=decay_gamma\n",
    "    def change_player(self):\n",
    "        \"\"\"A function for changing player\"\"\"\n",
    "        if self.player=='agent':\n",
    "            self.player='dummy'\n",
    "        else:\n",
    "            self.player='agent'\n",
    "    def get_reward(self):\n",
    "        \"\"\"This function determines the reward to give.\n",
    "            Returns the reward.\"\"\"\n",
    "        if self.player =='agent':\n",
    "            if sum(self.board)==1:\n",
    "                return 1 \n",
    "        if self.is_game_over():\n",
    "            if self.player == 'agent': #if player 1 takes last stick\n",
    "                return -1\n",
    "            else:\n",
    "                return 1 # in player 2 takes last stick\n",
    "        else:\n",
    "            return 0 #if game is not over\n",
    "    def get_legal_actions(self):\n",
    "        \"\"\"This function determines all legal actions on the current board state.\n",
    "            Returns a list of legal actions.\"\"\"\n",
    "        actions = []\n",
    "        for i in np.nonzero(self.board)[0]:#indices of non-zero piles\n",
    "            for j in range(1, self.board[i]+1): #number of stones\n",
    "                actions.append((i, j))\n",
    "        return actions\n",
    "    def is_game_over(self):\n",
    "        \"\"\"A function for determining whether the game is over.\n",
    "            Returns True if the game is over and False otherwise\"\"\"\n",
    "        return sum(self.board)==0\n",
    "    def possible_next_states(self, state):\n",
    "        \"\"\"Function to consider all possible board states which is obtainable from a given state.\n",
    "            Input is a board state for which you want to find all possible obtainable states from.\n",
    "            Returns a list of all possible obtainable board states.\"\"\"\n",
    "        list_to_return=[]\n",
    "        for i in range(state[0]+1):\n",
    "            for j in range(state[1]+1):\n",
    "                list_to_return.append([state[0]-i, state[1]-j])\n",
    "        if state in list_to_return:\n",
    "            list_to_return.remove(state)\n",
    "        return list_to_return\n",
    "    def feedReward(self, reward):\n",
    "        \"\"\"Function for updating the Q-table\"\"\"\n",
    "        for st in reversed(self.states):  # goes through all saved board states of this game\n",
    "            possible_next_st=self.possible_next_states(st)\n",
    "            temp=-1000\n",
    "            for i in possible_next_st:\n",
    "                if self.states_value.get(str(i)) is not None and self.states_value.get(str(i))>temp:\n",
    "                    temp=self.states_value.get(str(i))\n",
    "            if self.states_value.get(str(st)) is None: \n",
    "                self.states_value[str(st)] = 0  # initialise a value for the state\n",
    "            self.states_value[str(st)] += self.lr * (reward -self.gamma*temp- self.states_value[str(st)])\n",
    "    def reset(self,init_state):\n",
    "        \"\"\"A function for resetting the game after an ended game.\"\"\"\n",
    "        self.board=init_state\n",
    "        self.states=[]\n",
    "        self.number_of_piles=np.count_nonzero(self.board)\n",
    "        self.player=self.starting_player\n",
    "        self.winner=None\n",
    "        return\n",
    "    def nim_sum(self, numbers):\n",
    "        \"\"\"Function for calculating the nim sum.\n",
    "            Input is a list of numbers.\n",
    "            Returns Nim sum of the numbers in the list.\"\"\"\n",
    "        binary_numbers = [bin(num)[2:].zfill(len(bin(max(numbers))) - 2) for num in numbers]\n",
    "        column_sums = [sum(int(binary[i]) for binary in binary_numbers) for i in range(len(binary_numbers[0]))]\n",
    "        nim_sum = ''.join(['0' if sum % 2 == 0 else '1' for sum in column_sums])\n",
    "        return int(nim_sum, 2)\n",
    "    def choose_optimal_action(self):\n",
    "        \"\"\"This function returns the optimal action, i.e. such that the nim sum is zero.\n",
    "        if this is not possible, then it returns a random action\"\"\"\n",
    "        if nim_sum(self.board)==0:\n",
    "            return self.choose_random_action()\n",
    "        else:\n",
    "            actions=self.get_legal_actions()\n",
    "            for a in actions:\n",
    "                test_board=self.board.copy()\n",
    "                pile_number, amount_to_remove=a\n",
    "                test_board[pile_number]-=amount_to_remove\n",
    "                if nim_sum(test_board)==0:\n",
    "                    return a\n",
    "    def choose_random_action(self):\n",
    "        \"\"\"A function for choosing an action randomly.\n",
    "            Returns an action.\"\"\"\n",
    "        action=self.get_legal_actions()\n",
    "        return random.choice(action)\n",
    "    def choose_smart_action(self):\n",
    "        \"\"\"A function for choosing an action according to the Q-table.\n",
    "        Returns an action.\"\"\"\n",
    "        actions=self.get_legal_actions()\n",
    "        value_max = -999\n",
    "        for p in actions:\n",
    "            board_copy=self.board.copy()\n",
    "            pile_number, amount_to_remove=p\n",
    "            board_copy[pile_number]-=amount_to_remove\n",
    "            next_board = board_copy\n",
    "            value = 0 if self.states_value.get(str(next_board)) is None else self.states_value.get(str(next_board))\n",
    "            if value >= value_max:\n",
    "                value_max = value\n",
    "                move = p\n",
    "        return move\n",
    "    def play_action(self, action):\n",
    "        \"\"\"play a given action.\"\"\"\n",
    "        pile_number, amount_to_remove=action\n",
    "        self.board[pile_number]-=amount_to_remove\n",
    "        return\n",
    "    def training_game(self, rounds=10):\n",
    "        \"\"\"The function for training the agent.\n",
    "            Input is the number of training games to be played\"\"\"\n",
    "        for i in range(rounds):\n",
    "            while not self.is_game_over():\n",
    "                if self.player=='dummy':\n",
    "                    move= self.choose_random_action()\n",
    "                else:\n",
    "                    if np.random.uniform(0,1)<= self.exp_rate:\n",
    "                        move = self.choose_random_action()\n",
    "                    else:\n",
    "                        move=self.choose_smart_action()\n",
    "                self.play_action(move)\n",
    "                if self.player=='agent':\n",
    "                    self.states.append(self.board.copy())\n",
    "                if self.is_game_over():\n",
    "                    self.winner=self.player\n",
    "                    list_of_winners.append(self.winner)\n",
    "                    if self.winner=='agent':\n",
    "                        self.feedReward(5)\n",
    "                    else:\n",
    "                        self.feedReward(-1)\n",
    "                    self.reset(initial_board.copy())\n",
    "                    break\n",
    "                else:\n",
    "                    self.change_player()\n",
    "    def train_against_pro(self, rounds=1000):\n",
    "        \"\"\"In this function, the agent is trained against a player who only performs optimal moves\n",
    "        - note that this player is still named dummy.\n",
    "            Input is the number of training games to be played.\"\"\"\n",
    "        for i in range(rounds):\n",
    "            while not self.is_game_over():\n",
    "                if self.player=='dummy':\n",
    "                    move= self.choose_optimal_action()\n",
    "                else:\n",
    "                    if np.random.uniform(0,1)<= self.exp_rate:\n",
    "                        move = self.choose_random_action()\n",
    "                    else:\n",
    "                        move=self.choose_smart_action()\n",
    "                self.play_action(move)\n",
    "                if self.player=='agent':\n",
    "                    self.states.append(self.board.copy())\n",
    "                    #print(self.board, self.states, 'hej')\n",
    "                if self.is_game_over():\n",
    "                    self.winner=self.player\n",
    "                    list_of_winners.append(self.winner)\n",
    "                    if self.winner=='agent':\n",
    "                        self.feedReward(100)\n",
    "                    else:\n",
    "                        self.feedReward(-1)\n",
    "                    self.reset(initial_board.copy())\n",
    "                    break\n",
    "                else:\n",
    "                    self.change_player()\n",
    "    def test_against_pro(self, rounds=1000):\n",
    "        \"\"\"A function for testing a given policy against a player performing optimal moves.\n",
    "            Input is the number of test games to be played.\"\"\"\n",
    "        for i in range(rounds):\n",
    "            while not self.is_game_over():\n",
    "                if self.player=='dummy':\n",
    "                    move= self.choose_optimal_action()\n",
    "                    #print('dummy chooses the following move', move)\n",
    "                else:\n",
    "                        move=self.choose_smart_action()\n",
    "                        #print('agent chooses the following move', move)\n",
    "                self.play_action(move)\n",
    "                #print('the board is now:', self.board, 'with nim sum:', self.nim_sum(self.board))\n",
    "                if self.is_game_over():\n",
    "                    self.winner=self.player\n",
    "                    list_of_winners.append(self.winner)\n",
    "                    self.reset(initial_board.copy())\n",
    "                    break\n",
    "                else:\n",
    "                    self.change_player()\n",
    "    def test_game(self, rounds=1000):\n",
    "        \"\"\"A function for testing a policy against a player with the random strategy.\n",
    "            Input is the number of test game to be played.\"\"\"\n",
    "        for i in range(rounds):\n",
    "            while not self.is_game_over():\n",
    "                if self.player=='dummy':\n",
    "                    move= self.choose_random_action()\n",
    "                else:\n",
    "                        move=self.choose_smart_action()\n",
    "                self.play_action(move)\n",
    "                if self.is_game_over():\n",
    "                    self.winner=self.player\n",
    "                    list_of_winners.append(self.winner)\n",
    "                    self.reset(initial_board.copy())\n",
    "                    break\n",
    "                else:\n",
    "                    self.change_player()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c62295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.30000000000000004, 0.5, 0.7000000000000001, 0.9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_alphas=[0.01*i for i in range(1,20,2)]\n",
    "list_of_gammas=[0.1*i for i in range(1,10,2)]\n",
    "list_of_epsilons=[0.1*i for i in range(1,10,2)]\n",
    "list_of_epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_alphas=[0.01*i for i in range(1,20,2)]\n",
    "list_of_gammas=[0.1*i for i in range(1,10,2)]\n",
    "list_of_epsilons=[0.1*i for i in range(1,10,2)]\n",
    "for alpha in list_of_alphas:\n",
    "    for gamma in list_of_gammas:\n",
    "        for epsilon in list_of_epsilons:\n",
    "            initial_board=[1,3,5]\n",
    "            nim=NimGame(initial_board)\n",
    "            nim.lr=alpha\n",
    "            nim.exp_rate=epsilon\n",
    "            nim.gamma=gamma\n",
    "            number_of_iterations=10\n",
    "            rounds_mean=[]\n",
    "            time_mean=[]\n",
    "            for i in range(number_of_iterations):\n",
    "                list_of_winners=[]\n",
    "                policy={}\n",
    "                nim.states_value=policy\n",
    "                total_rounds=0\n",
    "                rounds=1000\n",
    "                start_time=time.time()\n",
    "                while list_of_winners.count('agent')*100/rounds<100:\n",
    "                    list_of_winners=[]\n",
    "                    nim.train_against_pro(rounds)\n",
    "                    list_of_winners=[]\n",
    "                    nim.test_against_pro(rounds)\n",
    "                    total_rounds+=rounds\n",
    "                    #print('agent wins:', list_of_winners.count('agent')*100/rounds, total_rounds)\n",
    "                    if list_of_winners.count('agent')*100/rounds>max_win_rate:\n",
    "                        max_win_rate=list_of_winners.count('agent')*100/rounds\n",
    "                end_time=time.time()\n",
    "                rounds_mean.append(total_rounds)\n",
    "                time_mean.append(end_time-start_time)\n",
    "                #print(total_rounds, end_time-start_time)\n",
    "            \n",
    "            #print('In average, it took', np.mean(rounds_mean),'training games and', np.mean(time_mean), 'seconds to find an optimal policy.')\n",
    "            #print('alpha:',alpha, ', gamma:', gamma, ', epsilon:', epsilon)\n",
    "            print(np.mean(rounds_mean), np.mean(time_mean), alpha, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c257d",
   "metadata": {},
   "source": [
    "### This is what the program printed\n",
    "\n",
    "\n",
    "54400.0 6.605865263938904 0.01 0.1 0.1\n",
    "20400.0 2.546582651138306 0.01 0.1 0.30000000000000004\n",
    "16800.0 2.218331456184387 0.01 0.1 0.5\n",
    "16100.0 2.0976560592651365 0.01 0.1 0.7000000000000001\n",
    "26900.0 3.4539296865463256 0.01 0.1 0.9\n",
    "91400.0 11.223314332962037 0.01 0.30000000000000004 0.1\n",
    "38200.0 4.798337125778199 0.01 0.30000000000000004 0.30000000000000004\n",
    "30400.0 3.9691399335861206 0.01 0.30000000000000004 0.5\n",
    "33600.0 4.340031218528748 0.01 0.30000000000000004 0.7000000000000001\n",
    "56600.0 7.267593359947204 0.01 0.30000000000000004 0.9\n",
    "115000.0 14.055317282676697 0.01 0.5 0.1\n",
    "47800.0 5.960411119461059 0.01 0.5 0.30000000000000004\n",
    "37900.0 4.796879696846008 0.01 0.5 0.5\n",
    "41400.0 5.345577955245972 0.01 0.5 0.7000000000000001\n",
    "75500.0 9.705233931541443 0.01 0.5 0.9\n",
    "132400.0 16.89210138320923 0.01 0.7000000000000001 0.1\n",
    "52500.0 6.695010948181152 0.01 0.7000000000000001 0.30000000000000004\n",
    "41600.0 5.380018997192383 0.01 0.7000000000000001 0.5\n",
    "46600.0 6.018443536758423 0.01 0.7000000000000001 0.7000000000000001\n",
    "83900.0 10.811143279075623 0.01 0.7000000000000001 0.9\n",
    "137200.0 16.910699820518495 0.01 0.9 0.1\n",
    "56800.0 7.34582633972168 0.01 0.9 0.30000000000000004\n",
    "46800.0 6.136266899108887 0.01 0.9 0.5\n",
    "51400.0 6.633748483657837 0.01 0.9 0.7000000000000001\n",
    "95300.0 12.253316402435303 0.01 0.9 0.9\n",
    "17700.0 2.1876007556915282 0.03 0.1 0.1\n",
    "7600.0 0.9500716209411622 0.03 0.1 0.30000000000000004\n",
    "5900.0 0.757445502281189 0.03 0.1 0.5\n",
    "6100.0 0.7888650178909302 0.03 0.1 0.7000000000000001\n",
    "10400.0 1.3304452657699586 0.03 0.1 0.9\n",
    "32900.0 4.062986660003662 0.03 0.30000000000000004 0.1\n",
    "13400.0 1.700400161743164 0.03 0.30000000000000004 0.30000000000000004\n",
    "10500.0 1.349242877960205 0.03 0.30000000000000004 0.5\n",
    "11200.0 1.4565393924713135 0.03 0.30000000000000004 0.7000000000000001\n",
    "20900.0 2.6951905727386474 0.03 0.30000000000000004 0.9\n",
    "36900.0 4.610458731651306 0.03 0.5 0.1\n",
    "16500.0 2.0809727907180786 0.03 0.5 0.30000000000000004\n",
    "12100.0 1.5664000988006592 0.03 0.5 0.5\n",
    "14700.0 1.924274754524231 0.03 0.5 0.7000000000000001\n",
    "23300.0 3.014676308631897 0.03 0.5 0.9\n",
    "41200.0 5.463363742828369 0.03 0.7000000000000001 0.1\n",
    "17900.0 2.282658004760742 0.03 0.7000000000000001 0.30000000000000004\n",
    "14300.0 1.8537375211715699 0.03 0.7000000000000001 0.5\n",
    "15300.0 1.9965930461883545 0.03 0.7000000000000001 0.7000000000000001\n",
    "25700.0 3.332640218734741 0.03 0.7000000000000001 0.9\n",
    "45000.0 5.5858386039733885 0.03 0.9 0.1\n",
    "20000.0 2.5564598560333254 0.03 0.9 0.30000000000000004\n",
    "14700.0 1.9006131172180176 0.03 0.9 0.5\n",
    "17700.0 2.288687562942505 0.03 0.9 0.7000000000000001\n",
    "31200.0 4.034735250473022 0.03 0.9 0.9\n",
    "14000.0 1.7115816354751587 0.05 0.1 0.1\n",
    "4900.0 0.6270369768142701 0.05 0.1 0.30000000000000004\n",
    "3500.0 0.4442156791687012 0.05 0.1 0.5\n",
    "3200.0 0.409309983253479 0.05 0.1 0.7000000000000001\n",
    "6100.0 0.7857693433761597 0.05 0.1 0.9\n",
    "19400.0 2.387915086746216 0.05 0.30000000000000004 0.1\n",
    "8300.0 1.070654296875 0.05 0.30000000000000004 0.30000000000000004\n",
    "6600.0 0.8497924089431763 0.05 0.30000000000000004 0.5\n",
    "6700.0 0.8678466796875 0.05 0.30000000000000004 0.7000000000000001\n",
    "11400.0 1.4645888090133667 0.05 0.30000000000000004 0.9\n",
    "23100.0 2.895168995857239 0.05 0.5 0.1\n",
    "9900.0 1.2450314521789552 0.05 0.5 0.30000000000000004\n",
    "7800.0 1.0132437229156495 0.05 0.5 0.5\n",
    "8700.0 1.116224217414856 0.05 0.5 0.7000000000000001\n",
    "14300.0 1.8363401174545289 0.05 0.5 0.9\n",
    "25900.0 3.230182147026062 0.05 0.7000000000000001 0.1\n",
    "11600.0 1.460542368888855 0.05 0.7000000000000001 0.30000000000000004\n",
    "8600.0 1.1193601369857789 0.05 0.7000000000000001 0.5\n",
    "9600.0 1.2438376665115356 0.05 0.7000000000000001 0.7000000000000001\n",
    "16800.0 2.156690526008606 0.05 0.7000000000000001 0.9\n",
    "27300.0 3.3777499437332152 0.05 0.9 0.1\n",
    "12400.0 1.5758662939071655 0.05 0.9 0.30000000000000004\n",
    "9500.0 1.215079426765442 0.05 0.9 0.5\n",
    "10500.0 1.3591228246688842 0.05 0.9 0.7000000000000001\n",
    "20300.0 2.606812524795532 0.05 0.9 0.9\n",
    "9400.0 1.161474919319153 0.07 0.1 0.1\n",
    "3700.0 0.47504923343658445 0.07 0.1 0.30000000000000004\n",
    "3000.0 0.3767707109451294 0.07 0.1 0.5\n",
    "3100.0 0.39662353992462157 0.07 0.1 0.7000000000000001\n",
    "4800.0 0.6160403966903687 0.07 0.1 0.9\n",
    "13000.0 1.6120084285736085 0.07 0.30000000000000004 0.1\n",
    "6100.0 0.7883914947509766 0.07 0.30000000000000004 0.30000000000000004\n",
    "4500.0 0.587455439567566 0.07 0.30000000000000004 0.5\n",
    "4900.0 0.6314045190811157 0.07 0.30000000000000004 0.7000000000000001\n",
    "8000.0 1.030586552619934 0.07 0.30000000000000004 0.9\n",
    "18100.0 2.40663366317749 0.07 0.5 0.1\n",
    "6600.0 0.8307950258255005 0.07 0.5 0.30000000000000004\n",
    "5700.0 0.7286819219589233 0.07 0.5 0.5\n",
    "6700.0 0.8653172731399537 0.07 0.5 0.7000000000000001\n",
    "10500.0 1.3530909776687623 0.07 0.5 0.9\n",
    "19100.0 2.4030818939208984 0.07 0.7000000000000001 0.1\n",
    "8000.0 1.0128585338592528 0.07 0.7000000000000001 0.30000000000000004\n",
    "5800.0 0.7409590005874633 0.07 0.7000000000000001 0.5\n",
    "6800.0 0.8729534864425659 0.07 0.7000000000000001 0.7000000000000001\n",
    "10800.0 1.3907411098480225 0.07 0.7000000000000001 0.9\n",
    "21100.0 2.6601486682891844 0.07 0.9 0.1\n",
    "7400.0 0.9573254346847534 0.07 0.9 0.30000000000000004\n",
    "6900.0 0.8853067398071289 0.07 0.9 0.5\n",
    "7500.0 0.9662659645080567 0.07 0.9 0.7000000000000001\n",
    "13300.0 1.7121004343032837 0.07 0.9 0.9\n",
    "7000.0 0.877167010307312 0.09 0.1 0.1\n",
    "3200.0 0.39817490577697756 0.09 0.1 0.30000000000000004\n",
    "2100.0 0.2657524585723877 0.09 0.1 0.5\n",
    "2700.0 0.3447479248046875 0.09 0.1 0.7000000000000001\n",
    "3800.0 0.4851510524749756 0.09 0.1 0.9\n",
    "12000.0 1.4791327953338622 0.09 0.30000000000000004 0.1\n",
    "4700.0 0.6009609937667847 0.09 0.30000000000000004 0.30000000000000004\n",
    "3800.0 0.48763813972473147 0.09 0.30000000000000004 0.5\n",
    "4100.0 0.5299638032913208 0.09 0.30000000000000004 0.7000000000000001\n",
    "6500.0 0.8335980176925659 0.09 0.30000000000000004 0.9\n",
    "15400.0 1.897213053703308 0.09 0.5 0.1\n",
    "5600.0 0.7076650619506836 0.09 0.5 0.30000000000000004\n",
    "4600.0 0.5893559217453003 0.09 0.5 0.5\n",
    "4400.0 0.5717717409133911 0.09 0.5 0.7000000000000001\n",
    "8000.0 1.032082200050354 0.09 0.5 0.9\n",
    "13400.0 1.6631282567977905 0.09 0.7000000000000001 0.1\n",
    "6000.0 0.7739809989929199 0.09 0.7000000000000001 0.30000000000000004\n",
    "5000.0 0.6384347677230835 0.09 0.7000000000000001 0.5\n",
    "5200.0 0.6734694957733154 0.09 0.7000000000000001 0.7000000000000001\n",
    "9200.0 1.18148832321167 0.09 0.7000000000000001 0.9\n",
    "19800.0 2.4389530181884767 0.09 0.9 0.1\n",
    "6800.0 0.8645286560058594 0.09 0.9 0.30000000000000004\n",
    "5300.0 0.6971422433853149 0.09 0.9 0.5\n",
    "5700.0 0.7404067277908325 0.09 0.9 0.7000000000000001\n",
    "10900.0 1.401625657081604 0.09 0.9 0.9\n",
    "6700.0 0.8235293626785278 0.11 0.1 0.1\n",
    "2400.0 0.30350518226623535 0.11 0.1 0.30000000000000004\n",
    "2100.0 0.26966214179992676 0.11 0.1 0.5\n",
    "2200.0 0.2799672603607178 0.11 0.1 0.7000000000000001\n",
    "2700.0 0.34594295024871824 0.11 0.1 0.9\n",
    "8400.0 1.0439855575561523 0.11 0.30000000000000004 0.1\n",
    "3700.0 0.4675200700759888 0.11 0.30000000000000004 0.30000000000000004\n",
    "3200.0 0.4125957489013672 0.11 0.30000000000000004 0.5\n",
    "3400.0 0.43566222190856935 0.11 0.30000000000000004 0.7000000000000001\n",
    "5500.0 0.7047901630401612 0.11 0.30000000000000004 0.9\n",
    "10500.0 1.3315981388092042 0.11 0.5 0.1\n",
    "4700.0 0.6023809671401977 0.11 0.5 0.30000000000000004\n",
    "3800.0 0.4838422775268555 0.11 0.5 0.5\n",
    "4300.0 0.552120852470398 0.11 0.5 0.7000000000000001\n",
    "7700.0 0.9862978458404541 0.11 0.5 0.9\n",
    "11700.0 1.4546268939971925 0.11 0.7000000000000001 0.1\n",
    "5000.0 0.6322080612182617 0.11 0.7000000000000001 0.30000000000000004\n",
    "4300.0 0.5509825944900513 0.11 0.7000000000000001 0.5\n",
    "4700.0 0.6091274499893189 0.11 0.7000000000000001 0.7000000000000001\n",
    "8500.0 1.0928788661956788 0.11 0.7000000000000001 0.9\n",
    "18500.0 2.270965075492859 0.11 0.9 0.1\n",
    "5800.0 0.7501320362091064 0.11 0.9 0.30000000000000004\n",
    "4400.0 0.5667460918426513 0.11 0.9 0.5\n",
    "4500.0 0.5811226844787598 0.11 0.9 0.7000000000000001\n",
    "8900.0 1.1452609300613403 0.11 0.9 0.9\n",
    "6100.0 0.8339898824691773 0.13 0.1 0.1\n",
    "2200.0 0.2762604236602783 0.13 0.1 0.30000000000000004\n",
    "1800.0 0.23013579845428467 0.13 0.1 0.5\n",
    "1800.0 0.23038487434387206 0.13 0.1 0.7000000000000001\n",
    "2600.0 0.33269972801208497 0.13 0.1 0.9\n",
    "7700.0 0.9480060815811158 0.13 0.30000000000000004 0.1\n",
    "3800.0 0.4755197525024414 0.13 0.30000000000000004 0.30000000000000004\n",
    "2600.0 0.33149802684783936 0.13 0.30000000000000004 0.5\n",
    "2700.0 0.345818305015564 0.13 0.30000000000000004 0.7000000000000001\n",
    "4800.0 0.6153265714645386 0.13 0.30000000000000004 0.9\n",
    "10300.0 1.2720768451690674 0.13 0.5 0.1\n",
    "4100.0 0.5347757816314698 0.13 0.5 0.30000000000000004\n",
    "3400.0 0.43972880840301515 0.13 0.5 0.5\n",
    "3500.0 0.45083327293395997 0.13 0.5 0.7000000000000001\n",
    "5100.0 0.655206298828125 0.13 0.5 0.9\n",
    "11800.0 1.4667126178741454 0.13 0.7000000000000001 0.1\n",
    "4700.0 0.6060858726501465 0.13 0.7000000000000001 0.30000000000000004\n",
    "3400.0 0.4342501640319824 0.13 0.7000000000000001 0.5\n",
    "4100.0 0.5315658330917359 0.13 0.7000000000000001 0.7000000000000001\n",
    "7100.0 0.9131112813949585 0.13 0.7000000000000001 0.9\n",
    "11200.0 1.389155888557434 0.13 0.9 0.1\n",
    "5100.0 0.6411936521530152 0.13 0.9 0.30000000000000004\n",
    "4000.0 0.5180796384811401 0.13 0.9 0.5\n",
    "4500.0 0.5756556034088135 0.13 0.9 0.7000000000000001\n",
    "7600.0 0.9810837984085083 0.13 0.9 0.9\n",
    "4600.0 0.5640867471694946 0.15 0.1 0.1\n",
    "1900.0 0.23779876232147218 0.15 0.1 0.30000000000000004\n",
    "1900.0 0.24053120613098145 0.15 0.1 0.5\n",
    "1700.0 0.21579303741455078 0.15 0.1 0.7000000000000001\n",
    "2500.0 0.3188217878341675 0.15 0.1 0.9\n",
    "8100.0 0.9990598201751709 0.15 0.30000000000000004 0.1\n",
    "3000.0 0.37704198360443114 0.15 0.30000000000000004 0.30000000000000004\n",
    "2600.0 0.32734701633453367 0.15 0.30000000000000004 0.5\n",
    "2800.0 0.35742032527923584 0.15 0.30000000000000004 0.7000000000000001\n",
    "4400.0 0.5637786865234375 0.15 0.30000000000000004 0.9\n",
    "8500.0 1.055244016647339 0.15 0.5 0.1\n",
    "3500.0 0.4434426546096802 0.15 0.5 0.30000000000000004\n",
    "2700.0 0.34559504985809325 0.15 0.5 0.5\n",
    "3100.0 0.4002765417098999 0.15 0.5 0.7000000000000001\n",
    "4900.0 0.6292182445526123 0.15 0.5 0.9\n",
    "9800.0 1.2313106298446654 0.15 0.7000000000000001 0.1\n",
    "4000.0 0.508252763748169 0.15 0.7000000000000001 0.30000000000000004\n",
    "2900.0 0.3753349781036377 0.15 0.7000000000000001 0.5\n",
    "3500.0 0.44790427684783934 0.15 0.7000000000000001 0.7000000000000001\n",
    "5300.0 0.6813356399536132 0.15 0.7000000000000001 0.9\n",
    "10900.0 1.3455046892166138 0.15 0.9 0.1\n",
    "4200.0 0.5277354955673218 0.15 0.9 0.30000000000000004\n",
    "3100.0 0.40350797176361086 0.15 0.9 0.5\n",
    "3900.0 0.5034810543060303 0.15 0.9 0.7000000000000001\n",
    "6100.0 0.7860031127929688 0.15 0.9 0.9\n",
    "3800.0 0.46663694381713866 0.17 0.1 0.1\n",
    "1900.0 0.2371819019317627 0.17 0.1 0.30000000000000004\n",
    "1400.0 0.17777867317199708 0.17 0.1 0.5\n",
    "1500.0 0.19182796478271485 0.17 0.1 0.7000000000000001\n",
    "2000.0 0.25494239330291746 0.17 0.1 0.9\n",
    "6300.0 0.7758348226547241 0.17 0.30000000000000004 0.1\n",
    "2600.0 0.3252236843109131 0.17 0.30000000000000004 0.30000000000000004\n",
    "2000.0 0.2517982482910156 0.17 0.30000000000000004 0.5\n",
    "2400.0 0.3075207948684692 0.17 0.30000000000000004 0.7000000000000001\n",
    "3800.0 0.4881488561630249 0.17 0.30000000000000004 0.9\n",
    "8700.0 1.0704642295837403 0.17 0.5 0.1\n",
    "3200.0 0.4173693895339966 0.17 0.5 0.30000000000000004\n",
    "2400.0 0.3036945819854736 0.17 0.5 0.5\n",
    "2500.0 0.3179716348648071 0.17 0.5 0.7000000000000001\n",
    "3700.0 0.47311928272247317 0.17 0.5 0.9\n",
    "7800.0 0.9753851652145386 0.17 0.7000000000000001 0.1\n",
    "3200.0 0.4030888795852661 0.17 0.7000000000000001 0.30000000000000004\n",
    "3300.0 0.4272929191589355 0.17 0.7000000000000001 0.5\n",
    "2900.0 0.3720515727996826 0.17 0.7000000000000001 0.7000000000000001\n",
    "5200.0 0.6672865629196167 0.17 0.7000000000000001 0.9\n",
    "8700.0 1.0811856031417846 0.17 0.9 0.1\n",
    "3700.0 0.47278261184692383 0.17 0.9 0.30000000000000004\n",
    "3400.0 0.43359899520874023 0.17 0.9 0.5\n",
    "3200.0 0.4141425132751465 0.17 0.9 0.7000000000000001\n",
    "5200.0 0.6696152210235595 0.17 0.9 0.9\n",
    "3400.0 0.41766350269317626 0.19 0.1 0.1\n",
    "2000.0 0.27104122638702394 0.19 0.1 0.30000000000000004\n",
    "1400.0 0.17758519649505616 0.19 0.1 0.5\n",
    "1500.0 0.1917268991470337 0.19 0.1 0.7000000000000001\n",
    "1800.0 0.2269843339920044 0.19 0.1 0.9\n",
    "5400.0 0.6680469274520874 0.19 0.30000000000000004 0.1\n",
    "2300.0 0.28707199096679686 0.19 0.30000000000000004 0.30000000000000004\n",
    "2500.0 0.32055599689483644 0.19 0.30000000000000004 0.5\n",
    "2000.0 0.2565619707107544 0.19 0.30000000000000004 0.7000000000000001\n",
    "3900.0 0.4991289615631104 0.19 0.30000000000000004 0.9\n",
    "6000.0 0.7419610738754272 0.19 0.5 0.1\n",
    "2400.0 0.3006353139877319 0.19 0.5 0.30000000000000004\n",
    "2500.0 0.3208888053894043 0.19 0.5 0.5\n",
    "2400.0 0.3076744794845581 0.19 0.5 0.7000000000000001\n",
    "4700.0 0.5993292570114136 0.19 0.5 0.9\n",
    "8600.0 1.0581413507461548 0.19 0.7000000000000001 0.1\n",
    "3100.0 0.39866597652435304 0.19 0.7000000000000001 0.30000000000000004\n",
    "2400.0 0.30711076259613035 0.19 0.7000000000000001 0.5\n",
    "3000.0 0.38606722354888917 0.19 0.7000000000000001 0.7000000000000001\n",
    "4300.0 0.5532007932662963 0.19 0.7000000000000001 0.9\n",
    "8000.0 0.9915069341659546 0.19 0.9 0.1\n",
    "3200.0 0.4066309928894043 0.19 0.9 0.30000000000000004\n",
    "2500.0 0.3199321746826172 0.19 0.9 0.5\n",
    "3000.0 0.3845560073852539 0.19 0.9 0.7000000000000001\n",
    "5300.0 0.6782634735107422 0.19 0.9 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9de977",
   "metadata": {},
   "source": [
    "## The best ones were:\n",
    "\n",
    "\n",
    "\n",
    "3500.0 0.4442156791687012 0.05 0.1 0.5\n",
    "3200.0 0.409309983253479 0.05 0.1 0.7000000000000001\n",
    "\n",
    "3000.0 0.3767707109451294 0.07 0.1 0.5\n",
    "3100.0 0.39662353992462157 0.07 0.1 0.7000000000000001\n",
    "\n",
    "3200.0 0.39817490577697756 0.09 0.1 0.30000000000000004\n",
    "2100.0 0.2657524585723877 0.09 0.1 0.5\n",
    "2700.0 0.3447479248046875 0.09 0.1 0.7000000000000001\n",
    "3800.0 0.4851510524749756 0.09 0.1 0.9\n",
    "\n",
    "\n",
    "\n",
    "2400.0 0.30350518226623535         0.11 0.1 0.30000000000000004\n",
    "2100.0 0.26966214179992676         0.11 0.1 0.5\n",
    "2200.0 0.2799672603607178         0.11 0.1 0.7000000000000001\n",
    "2700.0 0.34594295024871824         0.11 0.1 0.9\n",
    "3700.0 0.4675200700759888         0.11 0.30000000000000004 0.30000000000000004\n",
    "3200.0 0.4125957489013672         0.11 0.30000000000000004 0.5\n",
    "3400.0 0.43566222190856935         0.11 0.30000000000000004 0.7000000000000001\n",
    "5500.0 0.7047901630401612         0.11 0.30000000000000004 0.9\n",
    "2200.0 0.2762604236602783         0.13 0.1 0.30000000000000004\n",
    "1800.0 0.23013579845428467         0.13 0.1 0.5\n",
    "1800.0 0.23038487434387206         0.13 0.1 0.7000000000000001\n",
    "2600.0 0.33269972801208497         0.13 0.1 0.9\n",
    "2600.0 0.33149802684783936         0.13 0.30000000000000004 0.5\n",
    "2700.0 0.345818305015564         0.13 0.30000000000000004 0.7000000000000001\n",
    "1900.0 0.23779876232147218         0.15 0.1 0.30000000000000004\n",
    "1900.0 0.24053120613098145         0.15 0.1 0.5\n",
    "1700.0 0.21579303741455078         0.15 0.1 0.7000000000000001\n",
    "2500.0 0.3188217878341675         0.15 0.1 0.9\n",
    "3000.0 0.37704198360443114         0.15 0.30000000000000004 0.30000000000000004\n",
    "2600.0 0.32734701633453367         0.15 0.30000000000000004 0.5\n",
    "2800.0 0.35742032527923584         0.15 0.30000000000000004 0.7000000000000001\n",
    "2700.0 0.34559504985809325         0.15 0.5 0.5\n",
    "3100.0 0.4002765417098999         0.15 0.5 0.7000000000000001\n",
    "2900.0 0.3753349781036377         0.15 0.7000000000000001 0.5\n",
    "1900.0 0.2371819019317627         0.17 0.1 0.30000000000000004\n",
    "1400.0 0.17777867317199708         0.17 0.1 0.5\n",
    "1500.0 0.19182796478271485         0.17 0.1 0.7000000000000001\n",
    "2000.0 0.25494239330291746         0.17 0.1 0.9\n",
    "2000.0 0.2517982482910156         0.17 0.30000000000000004 0.5\n",
    "2400.0 0.3075207948684692         0.17 0.30000000000000004 0.7\n",
    "2900.0 0.3720515727996826         0.17 0.7000000000000001 0.700\n",
    "2000.0 0.27104122638702394         0.19 0.1 0.30000000000000004\n",
    "1400.0 0.17758519649505616         0.19 0.1 0.5\n",
    "1500.0 0.1917268991470337         0.19 0.1 0.7000000000000001\n",
    "1800.0 0.2269843339920044         0.19 0.1 0.9\n",
    "2400.0 0.3006353139877319         0.19 0.5 0.30000000000000004\n",
    "2500.0 0.3208888053894043         0.19 0.5 0.5\n",
    "2400.0 0.3076744794845581         0.19 0.5 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01e557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
