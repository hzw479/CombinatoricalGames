{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d15ce",
   "metadata": {},
   "source": [
    "# PLAYING, TRAINING AND TESTING GAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710882d",
   "metadata": {},
   "source": [
    "In this cell we define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad14118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.9 #should decrease as it continues to gain a larger knowledge base.\n",
    "decay_gamma=1 #big gamma means thinking long term\n",
    "exp_rate=0.3\n",
    "starting_player=1\n",
    "init_board='0'\n",
    "n=8\n",
    "\n",
    "file_name = 'test41'\n",
    "policy_player1='poltest41'\n",
    "list_of_winners=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "807f95df",
   "metadata": {
    "code_folding": [
     2,
     12,
     25,
     36,
     45,
     52,
     61,
     69,
     81,
     90,
     119,
     184,
     216
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class seq_game:\n",
    "    def __init__(self, n):\n",
    "        self.n=n\n",
    "        self.IsEnd=False\n",
    "        self.Player=starting_player\n",
    "        self.board=init_board\n",
    "        self.p1_states=[]\n",
    "        self.exp_rate=exp_rate\n",
    "        self.lr = learning_rate  # should decrease as it continues to gain a larger knowledge base\n",
    "        self.decay_gamma = decay_gamma  # big gamma means thinking long term\n",
    "        self.states_value = {}  # dict for storing {board, weight}\n",
    "    def check_for_losing_move(self, board):\n",
    "        \"\"\"\n",
    "        Checks whether adding 0 or 1 are losing moves\n",
    "        :return returns a list of losing moves, i.e either [], [0], [1], [0,1]:\n",
    "        \"\"\"\n",
    "        current_board=board\n",
    "        list_of_losers=[]\n",
    "        for i in [0,1]:\n",
    "            possible_loser=current_board+str(i)\n",
    "            substring_to_test=possible_loser[(-self.n):]\n",
    "            if substring_to_test in current_board:\n",
    "                list_of_losers.append(i)\n",
    "        return list_of_losers\n",
    "    def check_for_winning_move(self):\n",
    "        \"\"\"\n",
    "        Assumes there are two non-losing moves. Checks whether one of these moves forces next player to lose\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        winning_move=[]\n",
    "        for i in [0,1]:\n",
    "            temp_board=self.board+str(i)\n",
    "            if len(self.check_for_losing_move(temp_board))==2:\n",
    "                winning_move.append(i)\n",
    "        return winning_move\n",
    "    def change_player(self):\n",
    "        \"\"\"\n",
    "        Function for changing current player\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        if self.Player==1:\n",
    "            self.Player=2\n",
    "        else:\n",
    "            self.Player=1\n",
    "    def update_board(self, move):\n",
    "        \"\"\"\n",
    "        updates board\n",
    "        :param move is a string:\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board+=move\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the game\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board = init_board\n",
    "        self.IsEnd = False\n",
    "        self.Player = starting_player\n",
    "        self.p1_states=[]\n",
    "    def savePolicy(self):\n",
    "        \"\"\"\n",
    "        function for saving states and weights for use for the trained agent\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        fw = open('pol' + file_name, 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "    def feedReward(self, reward):\n",
    "        \"\"\"\n",
    "        function for giving rewards to all board states from the finished game.\n",
    "        :param reward: reward to give. 1 or 0.\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        for st in reversed(self.p1_states):  # goes through all saved board states of this game\n",
    "            if self.states_value.get(\n",
    "                    st) is None:  # if it's not already in the dictionary (of board states of ALL games)\n",
    "                self.states_value[st] = 0  # initialise a value for the state\n",
    "            self.states_value[st] += self.lr * (\n",
    "                        self.decay_gamma * reward - self.states_value[st])  # update weight for each board state\n",
    "    def loadPolicy(self, file):\n",
    "        \"\"\"\n",
    "        function for loading states and weights for the trained agent.\n",
    "        :param file:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "    def smartmove(self, current_board):\n",
    "        \"\"\"\n",
    "        function for choosing an action. This is for player 1 already trained.\n",
    "            :param positions: available moves to make\n",
    "            :param current_board: board state\n",
    "            :return: returns action to make\n",
    "         \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(current_board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                value_max = -999\n",
    "                #print(self.board, current_board, 'board')\n",
    "                for p in [0,1]:\n",
    "                    next_board = current_board+str(p)\n",
    "                    value = 0 if self.states_value.get(next_board) is None else self.states_value.get(next_board)\n",
    "                    if value >= value_max:\n",
    "                        value_max = value\n",
    "                        move = str(p)\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "\n",
    "\n",
    "    def normalmove(self):\n",
    "        \"\"\"\n",
    "        :return: returns move\n",
    "        \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(self.board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                move = str(random.randint(0, 1))\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "    def training_game(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            #if i % 1000 == 0:\n",
    "            #    print(\"Rounds {}\".format(i))\n",
    "            while not self.IsEnd:\n",
    "                move=self.normalmove()\n",
    "                if move is not None:\n",
    "                    self.update_board(move)\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player==2:#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                        self.feedReward(0)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def training_game2(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                if self.Player==2:\n",
    "                    move = self.normalmove()\n",
    "                else:\n",
    "                    if np.random.uniform(0,1)<= self.exp_rate:\n",
    "                        move = self.normalmove()\n",
    "                    else:\n",
    "                        move=self.smartmove(self.board)\n",
    "                if move is not None:\n",
    "                    self.update_board(str(move))\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player==2:#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                        self.feedReward(0)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def smart_game(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                #print('PLAYER', self.Player)\n",
    "                losing_moves = self.check_for_losing_move(self.board)\n",
    "                if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                    non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                    move = str(non_losing_move[0])\n",
    "                elif len(losing_moves) == 0:\n",
    "                    winning_moves = self.check_for_winning_move()\n",
    "                    if len(winning_moves) > 0:\n",
    "                        move = str(winning_moves[0])\n",
    "                    else:\n",
    "                        \"\"\"HERE IS WHERE THE EXCITING STUFF HAPPENS\"\"\"\n",
    "                        if self.Player==2:\n",
    "                            move = str(random.randint(0, 1))\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                self.update_board(move)\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                #print(self.board)\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    #with open('Data', 'a') as f:  # saves winner\n",
    "                    #    f.write(self.board+', ')\n",
    "                    if self.Player == 2:\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def smart_game2(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                if self.Player==1:\n",
    "                    losing_moves = self.check_for_losing_move(self.board)\n",
    "                    if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                        non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                        move = str(non_losing_move[0])\n",
    "                    elif len(losing_moves) == 0:\n",
    "                        winning_moves = self.check_for_winning_move()\n",
    "                        if len(winning_moves) > 0:\n",
    "                            move = str(winning_moves[0])\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                self.update_board(move)\n",
    "                if self.Player==2:\n",
    "                    losing_moves = self.check_for_losing_move(self.board)\n",
    "                    if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                        non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                        move = str(non_losing_move[0])\n",
    "                    if len(losing_moves)<1:\n",
    "                        move=str(random.randint(0, 1))\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player == 2:\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db1f6270",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "play = seq_game(n)\n",
    "play.training_game2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53344725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 69\n"
     ]
    }
   ],
   "source": [
    "list_of_substrings=[]\n",
    "examples='0101111101010111011101011110110111000111110011110100111111110111111000101111'\n",
    "for i in range(len(examples)-7):\n",
    "    list_of_substrings.append(examples[i:i+8])\n",
    "len(list_of_substrings), list_of_substrings\n",
    "print(len(list_of_substrings), len(set(list_of_substrings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085e3a1",
   "metadata": {},
   "source": [
    "Below is for training until policy has more than x percent winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf78291",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 632\n",
      "648 352\n",
      "616 384\n",
      "453 547\n",
      "633 367\n",
      "717 283\n",
      "487 513\n",
      "662 338\n",
      "550 450\n",
      "687 313\n",
      "587 413\n",
      "761 239\n",
      "547 453\n",
      "598 402\n",
      "619 381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "while i==0:\n",
    "    play = seq_game(n)\n",
    "    play.training_game2(500)\n",
    "    #print(list_of_winners.count(1), list_of_winners.count(2))\n",
    "    list_of_winners = []\n",
    "    play.loadPolicy(policy_player1)\n",
    "    play.smart_game(1000)\n",
    "    print(list_of_winners.count(1), list_of_winners.count(2))\n",
    "    if list_of_winners.count(1)>800:\n",
    "        print('JUBII')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23def817",
   "metadata": {},
   "source": [
    "Below is for testing a certain policy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6154586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754 246\n"
     ]
    }
   ],
   "source": [
    "play=seq_game(n)\n",
    "\n",
    "list_of_winners=[]\n",
    "play.loadPolicy('goodpolicy!')\n",
    "play.smart_game(1000)\n",
    "print(list_of_winners.count(1), list_of_winners.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1246bb",
   "metadata": {},
   "source": [
    "# BELOW IS FOR ANALYZING POLICY FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d066c7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009908480215936573 0.0002993008995001\n"
     ]
    }
   ],
   "source": [
    "fr = open('goodpolicy!', 'rb')\n",
    "hej = pickle.load(fr)\n",
    "print(hej['0100'], hej['0101'])\n",
    "hejkey=list(iter(hej))\n",
    "max_value = max(hej.values())\n",
    "value = {i for i in hej if hej[i]==max_value}\n",
    "#print(\"key by value:\",value)\n",
    "from collections import Counter\n",
    "hej2=dict(Counter(hej).most_common(15))\n",
    "#print(hej2)\n",
    "#print(len(max(hejkey, key = len)))\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a701a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
