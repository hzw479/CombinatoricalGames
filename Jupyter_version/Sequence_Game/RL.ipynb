{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d15ce",
   "metadata": {},
   "source": [
    "# PLAYING, TRAINING AND TESTING GAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710882d",
   "metadata": {},
   "source": [
    "In this cell we define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad14118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.9 #should decrease as it continues to gain a larger knowledge base.\n",
    "decay_gamma=1 #big gamma means thinking long term\n",
    "exp_rate=0.2\n",
    "starting_player=1\n",
    "init_board='0'\n",
    "n=8\n",
    "\n",
    "file_name = 'test41'\n",
    "policy_player1='poltest41'\n",
    "list_of_winners=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807f95df",
   "metadata": {
    "code_folding": [
     2,
     12,
     25,
     36,
     45,
     52,
     61,
     69,
     81,
     90,
     158,
     184,
     216
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class seq_game:\n",
    "    def __init__(self, n):\n",
    "        self.n=n\n",
    "        self.IsEnd=False\n",
    "        self.Player=starting_player\n",
    "        self.board=init_board\n",
    "        self.p1_states=[]\n",
    "        self.exp_rate=exp_rate\n",
    "        self.lr = learning_rate  # should decrease as it continues to gain a larger knowledge base\n",
    "        self.decay_gamma = decay_gamma  # big gamma means thinking long term\n",
    "        self.states_value = {}  # dict for storing {board, weight}\n",
    "    def check_for_losing_move(self, board):\n",
    "        \"\"\"\n",
    "        Checks whether adding 0 or 1 are losing moves\n",
    "        :return returns a list of losing moves, i.e either [], [0], [1], [0,1]:\n",
    "        \"\"\"\n",
    "        current_board=board\n",
    "        list_of_losers=[]\n",
    "        for i in [0,1]:\n",
    "            possible_loser=current_board+str(i)\n",
    "            substring_to_test=possible_loser[(-self.n):]\n",
    "            if substring_to_test in current_board:\n",
    "                list_of_losers.append(i)\n",
    "        return list_of_losers\n",
    "    def check_for_winning_move(self):\n",
    "        \"\"\"\n",
    "        Assumes there are two non-losing moves. Checks whether one of these moves forces next player to lose\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        winning_move=[]\n",
    "        for i in [0,1]:\n",
    "            temp_board=self.board+str(i)\n",
    "            if len(self.check_for_losing_move(temp_board))==2:\n",
    "                winning_move.append(i)\n",
    "        return winning_move\n",
    "    def change_player(self):\n",
    "        \"\"\"\n",
    "        Function for changing current player\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        if self.Player==1:\n",
    "            self.Player=2\n",
    "        else:\n",
    "            self.Player=1\n",
    "    def update_board(self, move):\n",
    "        \"\"\"\n",
    "        updates board\n",
    "        :param move is a string:\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board+=move\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the game\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board = init_board\n",
    "        self.IsEnd = False\n",
    "        self.Player = starting_player\n",
    "        self.p1_states=[]\n",
    "    def savePolicy(self):\n",
    "        \"\"\"\n",
    "        function for saving states and weights for use for the trained agent\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        fw = open('pol' + file_name, 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "    def feedReward(self, reward):\n",
    "        \"\"\"\n",
    "        function for giving rewards to all board states from the finished game.\n",
    "        :param reward: reward to give. 1 or 0.\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        for st in reversed(self.p1_states):  # goes through all saved board states of this game\n",
    "            if self.states_value.get(\n",
    "                    st) is None:  # if it's not already in the dictionary (of board states of ALL games)\n",
    "                self.states_value[st] = 0  # initialise a value for the state\n",
    "            self.states_value[st] += self.lr * (\n",
    "                        self.decay_gamma * reward - self.states_value[st])  # update weight for each board state\n",
    "    def loadPolicy(self, file):\n",
    "        \"\"\"\n",
    "        function for loading states and weights for the trained agent.\n",
    "        :param file:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "    def smartmove(self, current_board):\n",
    "        \"\"\"\n",
    "        function for choosing an action. This is for player 1 already trained.\n",
    "            :param positions: available moves to make\n",
    "            :param current_board: board state\n",
    "            :return: returns action to make\n",
    "         \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(current_board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                value_max = -999\n",
    "                #print(self.board, current_board, 'board')\n",
    "                for p in [0,1]:\n",
    "                    next_board = current_board+str(p)\n",
    "                    value = 0 if self.states_value.get(next_board) is None else self.states_value.get(next_board)\n",
    "                    if value >= value_max:\n",
    "                        value_max = value\n",
    "                        move = str(p)\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "\n",
    "\n",
    "    def normalmove(self):\n",
    "        \"\"\"\n",
    "        :return: returns move\n",
    "        \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(self.board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                move = str(random.randint(0, 1))\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "    def training_game(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            #if i % 1000 == 0:\n",
    "            #    print(\"Rounds {}\".format(i))\n",
    "            while not self.IsEnd:\n",
    "                move=self.normalmove()\n",
    "                if move is not None:\n",
    "                    self.update_board(move)\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player==2:#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                        self.feedReward(0)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def training_game2(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                if self.Player==2:\n",
    "                    move = self.normalmove()\n",
    "                else:\n",
    "                    if np.random.uniform(0,1)<= self.exp_rate:\n",
    "                        move = self.normalmove()\n",
    "                    else:\n",
    "                        move=self.smartmove(self.board)\n",
    "                if move is not None:\n",
    "                    self.update_board(str(move))\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player==2:#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                        self.feedReward(0)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def smart_game(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                #print('PLAYER', self.Player)\n",
    "                losing_moves = self.check_for_losing_move(self.board)\n",
    "                if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                    non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                    move = str(non_losing_move[0])\n",
    "                elif len(losing_moves) == 0:\n",
    "                    winning_moves = self.check_for_winning_move()\n",
    "                    if len(winning_moves) > 0:\n",
    "                        move = str(winning_moves[0])\n",
    "                    else:\n",
    "                        \"\"\"HERE IS WHERE THE EXCITING STUFF HAPPENS\"\"\"\n",
    "                        if self.Player==2:\n",
    "                            move = str(random.randint(0, 1))\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                self.update_board(move)\n",
    "                if self.Player == 1:\n",
    "                    self.p1_states.append(self.board)\n",
    "                #print(self.board)\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    #with open('Data', 'a') as f:  # saves winner\n",
    "                    #    f.write(self.board+', ')\n",
    "                    if self.Player == 2:\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def smart_game2(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                if self.Player==1:\n",
    "                    losing_moves = self.check_for_losing_move(self.board)\n",
    "                    if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                        non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                        move = str(non_losing_move[0])\n",
    "                    elif len(losing_moves) == 0:\n",
    "                        winning_moves = self.check_for_winning_move()\n",
    "                        if len(winning_moves) > 0:\n",
    "                            move = str(winning_moves[0])\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                self.update_board(move)\n",
    "                if self.Player==2:\n",
    "                    losing_moves = self.check_for_losing_move(self.board)\n",
    "                    if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                        non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                        move = str(non_losing_move[0])\n",
    "                    if len(losing_moves)<1:\n",
    "                        move=str(random.randint(0, 1))\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player == 2:\n",
    "                        list_of_winners.append(1)\n",
    "                    else:\n",
    "                        list_of_winners.append(2)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1f6270",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "play = seq_game(n)\n",
    "play.training_game(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e44ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef545f79",
   "metadata": {},
   "source": [
    "Below is for testing if a substring has repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53344725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 256\n"
     ]
    }
   ],
   "source": [
    "list_of_substrings=[]\n",
    "examples='01010111100100111101000100100101001110001110010101000010011010010111110111011111101011000110101110100110010110011101010010001010001111111100110110100000000100001110110000011110001000110011000011011110110111000000110001011010101011011001000001011100111110000101011'\n",
    "for i in range(len(examples)-7):\n",
    "    list_of_substrings.append(examples[i:i+8])\n",
    "len(list_of_substrings), list_of_substrings\n",
    "print(len(list_of_substrings), len(set(list_of_substrings)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085e3a1",
   "metadata": {},
   "source": [
    "Below is for training until policy has more than x percent winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf78291",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 245\n",
      "706 294\n",
      "257 743\n",
      "742 258\n",
      "709 291\n",
      "726 274\n",
      "644 356\n",
      "683 317\n",
      "640 360\n",
      "206 794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f7/616lwfzj0pbbbb39xctk67l00000gn/T/ipykernel_91392/2317106311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_game2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(list_of_winners.count(1), list_of_winners.count(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlist_of_winners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/616lwfzj0pbbbb39xctk67l00000gn/T/ipykernel_91392/3966067066.py\u001b[0m in \u001b[0;36mtraining_game2\u001b[0;34m(self, rounds)\u001b[0m\n\u001b[1;32m    165\u001b[0m                         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                         \u001b[0mmove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmartmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/616lwfzj0pbbbb39xctk67l00000gn/T/ipykernel_91392/3966067066.py\u001b[0m in \u001b[0;36msmartmove\u001b[0;34m(self, current_board)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_losing_move\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosing_moves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mwinning_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_for_winning_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinning_moves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinning_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/616lwfzj0pbbbb39xctk67l00000gn/T/ipykernel_91392/3966067066.py\u001b[0m in \u001b[0;36mcheck_for_winning_move\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtemp_board\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_for_losing_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_board\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mwinning_move\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwinning_move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f7/616lwfzj0pbbbb39xctk67l00000gn/T/ipykernel_91392/3966067066.py\u001b[0m in \u001b[0;36mcheck_for_losing_move\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlist_of_losers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpossible_loser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_board\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0msubstring_to_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpossible_loser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubstring_to_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_board\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "while i==0:\n",
    "    play = seq_game(n)\n",
    "    play.training_game2(500)\n",
    "    #print(list_of_winners.count(1), list_of_winners.count(2))\n",
    "    list_of_winners = []\n",
    "    play.loadPolicy(policy_player1)\n",
    "    play.smart_game(1000)\n",
    "    #print(list_of_winners.count(1), list_of_winners.count(2))\n",
    "    if list_of_winners.count(1)>780:\n",
    "   #     print('JUBII')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23def817",
   "metadata": {},
   "source": [
    "Below is for testing a certain policy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6154586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770 230\n"
     ]
    }
   ],
   "source": [
    "play=seq_game(n)\n",
    "\n",
    "list_of_winners=[]\n",
    "play.loadPolicy('goodpolicy!')\n",
    "play.smart_game(1000)\n",
    "print(list_of_winners.count(1), list_of_winners.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1246bb",
   "metadata": {},
   "source": [
    "# BELOW IS FOR ANALYZING POLICY FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d066c7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009908480215936573 0.0002993008995001\n"
     ]
    }
   ],
   "source": [
    "fr = open('goodpolicy!', 'rb')\n",
    "hej = pickle.load(fr)\n",
    "print(hej['0100'], hej['0101'])\n",
    "hejkey=list(iter(hej))\n",
    "max_value = max(hej.values())\n",
    "value = {i for i in hej if hej[i]==max_value}\n",
    "#print(\"key by value:\",value)\n",
    "from collections import Counter\n",
    "hej2=dict(Counter(hej).most_common(15))\n",
    "#print(hej2)\n",
    "#print(len(max(hejkey, key = len)))\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a701a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66512fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b9253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
