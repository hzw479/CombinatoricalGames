{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d15ce",
   "metadata": {},
   "source": [
    "# PLAYING, TRAINING AND TESTING GAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710882d",
   "metadata": {},
   "source": [
    "In this cell we define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad14118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "decay_gamma=0.9\n",
    "exp_rate=0.3\n",
    "starting_player='agent'\n",
    "init_board=''\n",
    "n=4\n",
    "file_name = '61'\n",
    "policy_player1='pol61'\n",
    "list_of_winners=[]\n",
    "end_game_big=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807f95df",
   "metadata": {
    "code_folding": [
     2,
     14,
     27,
     38,
     47,
     54,
     64,
     72,
     84,
     93,
     120,
     137,
     185,
     217,
     255,
     292
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#constructs the game class\n",
    "class seq_game:\n",
    "    def __init__(self, n):\n",
    "        self.n=n\n",
    "        self.IsEnd=False\n",
    "        self.Player=starting_player\n",
    "        self.board=init_board\n",
    "        self.agent_states=[]\n",
    "        self.exp_rate=exp_rate\n",
    "        self.lr = learning_rate  # should decrease as it continues to gain a larger knowledge base\n",
    "        self.decay_gamma = decay_gamma  # big gamma means thinking long term\n",
    "        self.states_value = {}  # dict for storing {board, weight}\n",
    "        self.end_game_list=[0,0]\n",
    "        self.winner=None\n",
    "    def check_for_losing_move(self, board):\n",
    "        \"\"\"\n",
    "        Checks whether adding 0 or 1 are losing moves\n",
    "        :return returns a list of losing moves, i.e either [], [0], [1], [0,1]:\n",
    "        \"\"\"\n",
    "        current_board=board\n",
    "        list_of_losers=[]\n",
    "        for i in [0,1]:\n",
    "            possible_loser=current_board+str(i)\n",
    "            substring_to_test=possible_loser[(-self.n):]\n",
    "            if substring_to_test in current_board:\n",
    "                list_of_losers.append(i)\n",
    "        return list_of_losers\n",
    "    def check_for_winning_move(self):\n",
    "        \"\"\"\n",
    "        Assumes there are two non-losing moves. Checks whether one of these moves forces next player to lose\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        winning_move=[]\n",
    "        for i in [0,1]:\n",
    "            temp_board=self.board+str(i)\n",
    "            if len(self.check_for_losing_move(temp_board))==2:\n",
    "                winning_move.append(i)\n",
    "        return winning_move\n",
    "    def change_player(self):\n",
    "        \"\"\"\n",
    "        Function for changing current player\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        if self.Player=='agent':\n",
    "            self.Player='dummy'\n",
    "        else:\n",
    "            self.Player='agent'\n",
    "    def update_board(self, move):\n",
    "        \"\"\"\n",
    "        updates board\n",
    "        :param move is a string:\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board+=move\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the game\n",
    "        :return: returns none\n",
    "        \"\"\"\n",
    "        self.board = init_board\n",
    "        self.IsEnd = False\n",
    "        self.Player = starting_player\n",
    "        self.agent_states=[]\n",
    "        self.winner=None\n",
    "    def savePolicy(self):\n",
    "        \"\"\"\n",
    "        function for saving states and weights for use for the trained agent\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        fw = open('pol' + file_name, 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "    def feedReward(self, reward):\n",
    "        \"\"\"\n",
    "        function for giving rewards to all board states from the finished game.\n",
    "        :param reward: reward to give. 1 or 0.\n",
    "        :return: returns None\n",
    "        \"\"\"\n",
    "        for st in reversed(self.agent_states):  # goes through all saved board states of this game\n",
    "            if self.states_value.get(\n",
    "                    st) is None:  # if it's not already in the dictionary (of board states of ALL games)\n",
    "                self.states_value[st] = 0  # initialise a value for the state\n",
    "            self.states_value[st] += self.lr * (\n",
    "                        self.decay_gamma * reward - self.states_value[st])  # update weight for each board state\n",
    "    def loadPolicy(self, file):\n",
    "        \"\"\"\n",
    "        function for loading states and weights for the trained agent.\n",
    "        :param file:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "    def smartmove(self, current_board):\n",
    "        \"\"\"\n",
    "        function for choosing an action. This is for player 1 already trained.\n",
    "            :param positions: available moves to make\n",
    "            :param current_board: board state\n",
    "            :return: returns action to make\n",
    "         \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(current_board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                value_max = -999\n",
    "                #print(self.board, current_board, 'board')\n",
    "                for p in [0,1]:\n",
    "                    next_board = current_board+str(p)\n",
    "                    value = 0 if self.states_value.get(next_board) is None else self.states_value.get(next_board)\n",
    "                    if value >= value_max:\n",
    "                        value_max = value\n",
    "                        move = str(p)\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "    def normalmove(self):\n",
    "        \"\"\"\n",
    "        :return: returns move\n",
    "        \"\"\"\n",
    "        losing_moves = self.check_for_losing_move(self.board)\n",
    "        if len(losing_moves) == 1:  # if only one non-losing move\n",
    "            non_losing_move = list({0, 1} - set(losing_moves))\n",
    "            move = str(non_losing_move[0])\n",
    "        elif len(losing_moves) == 0:\n",
    "            winning_moves = self.check_for_winning_move()\n",
    "            if len(winning_moves) > 0:\n",
    "                move = str(winning_moves[0])\n",
    "            else:\n",
    "                move = str(random.randint(0, 1))\n",
    "        else:\n",
    "            move= None\n",
    "        return move\n",
    "    def training_game_(self, rounds=1000):\n",
    "        for i in range(rounds):\n",
    "            #if i % 1000 == 0:\n",
    "            #    print(\"Rounds {}\".format(i))\n",
    "            while not self.IsEnd:\n",
    "                move=self.normalmove()\n",
    "                if move is not None:\n",
    "                    self.update_board(move)\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player=='dummy':#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append('agent')\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                        self.feedReward(0)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 'agent':\n",
    "                    self.agent_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset() #DONT USE THIS\n",
    "    def training_game(self, rounds=10):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                if self.Player=='dummy':\n",
    "                    move = self.normalmove()\n",
    "                else:\n",
    "                    if np.random.uniform(0,1)<= self.exp_rate:\n",
    "                        move = self.normalmove()\n",
    "                    else:\n",
    "                        move=self.smartmove(self.board)\n",
    "                if move is not None:\n",
    "                    self.update_board(str(move))\n",
    "                else:\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player=='dummy':#if player 1 has won\n",
    "                        self.feedReward(1)\n",
    "                        self.savePolicy()\n",
    "                        list_of_winners.append('agent')\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                        self.feedReward(-1)\n",
    "                        self.savePolicy()\n",
    "                if self.Player == 'agent':\n",
    "                    self.agent_states.append(self.board)\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def testing_game(self, rounds=1000):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                #print('PLAYER', self.Player)\n",
    "                losing_moves = self.check_for_losing_move(self.board)\n",
    "                if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                    non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                    move = str(non_losing_move[0])\n",
    "                elif len(losing_moves) == 0:\n",
    "                    winning_moves = self.check_for_winning_move()\n",
    "                    if len(winning_moves) > 0:\n",
    "                        move = str(winning_moves[0])\n",
    "                    else:\n",
    "                        \"\"\"HERE IS WHERE THE EXCITING STUFF HAPPENS\"\"\"\n",
    "                        if self.Player=='dummy':\n",
    "                            move = str(random.randint(0, 1))\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                self.update_board(move)\n",
    "                if self.Player == 'agent':\n",
    "                    self.agent_states.append(self.board)\n",
    "                #print(self.board)\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    #with open('Data', 'a') as f:  # saves winner\n",
    "                    #    f.write(self.board+', ')\n",
    "                    if self.Player == 'dummy':\n",
    "                        list_of_winners.append('agent')\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                self.change_player()\n",
    "            self.reset()\n",
    "    def end_game_testing(self, rounds=1000):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                losing_moves = self.check_for_losing_move(self.board)\n",
    "                if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                    if self.Player=='dummy':\n",
    "                        self.end_game_list.append('x')\n",
    "                    else:\n",
    "                        self.end_game_list.append('x')\n",
    "                    non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                    move = str(non_losing_move[0])\n",
    "                elif len(losing_moves) == 0:\n",
    "                    winning_moves = self.check_for_winning_move()\n",
    "                    if len(winning_moves) > 0:\n",
    "                        move = str(winning_moves[0])\n",
    "                        self.end_game_list.append('w')\n",
    "                    else:\n",
    "                        if self.Player=='dummy':\n",
    "                            move = str(random.randint(0, 1))\n",
    "                            self.end_game_list.append(0)\n",
    "                        else:\n",
    "                            move=self.smartmove(self.board)\n",
    "                            self.end_game_list.append(0)\n",
    "                self.update_board(move)\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player == 'dummy':\n",
    "                        list_of_winners.append('agent')\n",
    "                        self.winner='agent'\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                        self.winner='dummy'\n",
    "                self.change_player()\n",
    "            #print(self.end_game_agent)\n",
    "            end_game_big.append((self.end_game_list, self.winner))\n",
    "            self.reset()\n",
    "            self.end_game_list=[0,0]\n",
    "\n",
    "    def end_game_random(self, rounds=1000):\n",
    "        for i in range(rounds):\n",
    "            while not self.IsEnd:\n",
    "                losing_moves = self.check_for_losing_move(self.board)\n",
    "                if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                    if self.Player=='dummy':\n",
    "                        self.end_game_list.append('x')\n",
    "                    else:\n",
    "                        self.end_game_list.append('x')\n",
    "                    non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                    move = str(non_losing_move[0])\n",
    "                elif len(losing_moves) == 0:\n",
    "                    winning_moves = self.check_for_winning_move()\n",
    "                    if len(winning_moves) > 0:\n",
    "                        move = str(winning_moves[0])\n",
    "                        self.end_game_list.append('w')\n",
    "                    else:\n",
    "                        if self.Player=='dummy':\n",
    "                            move = str(random.randint(0, 1))\n",
    "                            self.end_game_list.append(0)\n",
    "                        else:\n",
    "                            move=str(random.randint(0, 1))\n",
    "                            self.end_game_list.append(0)\n",
    "                self.update_board(move)\n",
    "                if len(losing_moves) == 2:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player == 'dummy':\n",
    "                        list_of_winners.append('agent')\n",
    "                        self.winner='agent'\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                        self.winner='dummy'\n",
    "                self.change_player()\n",
    "            #print(self.end_game_agent)\n",
    "            end_game_big.append((self.end_game_list, self.winner))\n",
    "            self.reset()\n",
    "            self.end_game_list=[0,0]\n",
    "    def change_strategy(self, rounds=1000):\n",
    "        \"\"\"Changing strategy\"\"\"\n",
    "        for i in range(rounds):\n",
    "            agent_move=1\n",
    "            while not self.IsEnd:\n",
    "                if self.Player=='dummy':\n",
    "                    losing_moves=self.check_for_losing_move(self.board)\n",
    "                    move=self.normalmove()\n",
    "                else:\n",
    "                    losing_moves = self.check_for_losing_move(self.board)\n",
    "                    if len(losing_moves) == 1:  # if only one non-losing move\n",
    "                        non_losing_move = list({0, 1} - set(losing_moves))\n",
    "                        move = str(non_losing_move[0])\n",
    "                        agent_move=1-int(move)\n",
    "                    elif len(losing_moves) == 0:\n",
    "                        winning_moves = self.check_for_winning_move()\n",
    "                        if len(winning_moves) > 0:\n",
    "                            move = str(winning_moves[0])\n",
    "                            agent_move=1-int(move)\n",
    "                        else:\n",
    "                            move = str(agent_move)\n",
    "                            agent_move=1-int(move)\n",
    "                    else:\n",
    "                        move=None\n",
    "                if move is None:  # GAME OVER\n",
    "                    self.IsEnd = True\n",
    "                    if self.Player == 'dummy':\n",
    "                        list_of_winners.append('agent')\n",
    "                    else:\n",
    "                        list_of_winners.append('dummy')\n",
    "                        losing_games.append(self.board)\n",
    "                else:\n",
    "                    self.update_board(move)\n",
    "                self.change_player()\n",
    "            self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4feeafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "play = seq_game(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085e3a1",
   "metadata": {},
   "source": [
    "Below is for training until policy has more than x percent winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf78291",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "agent wins 78.9 percent of the test games, the Q-table has 1091 entries after 1000\n",
      "agent wins 83.2 percent of the test games, the Q-table has 1489 entries after 2000\n",
      "agent wins 83.9 percent of the test games, the Q-table has 1693 entries after 3000\n",
      "agent wins 93.3 percent of the test games, the Q-table has 1848 entries after 4000\n",
      "agent wins 90.1 percent of the test games, the Q-table has 2017 entries after 5000\n",
      "agent wins 91.3 percent of the test games, the Q-table has 2102 entries after 6000\n",
      "agent wins 82.3 percent of the test games, the Q-table has 2162 entries after 7000\n",
      "agent wins 93.9 percent of the test games, the Q-table has 2240 entries after 8000\n",
      "agent wins 97.8 percent of the test games, the Q-table has 2293 entries after 9000\n",
      "agent wins 89.1 percent of the test games, the Q-table has 2333 entries after 10000\n",
      "agent wins 89.5 percent of the test games, the Q-table has 2365 entries after 11000\n",
      "agent wins 94.2 percent of the test games, the Q-table has 2396 entries after 12000\n",
      "agent wins 91.6 percent of the test games, the Q-table has 2431 entries after 13000\n",
      "agent wins 95.8 percent of the test games, the Q-table has 2446 entries after 14000\n",
      "agent wins 100.0 percent of the test games, the Q-table has 2467 entries after 15000\n",
      "it took 5.055 seconds to finish\n"
     ]
    }
   ],
   "source": [
    "play = seq_game(n)\n",
    "rounds=1000\n",
    "total_rounds=0\n",
    "list_of_winners=[]\n",
    "print(len(play.states_value))\n",
    "start_time=time.time()\n",
    "while list_of_winners.count('agent')*100/rounds <100:\n",
    "    list_of_winners = []\n",
    "    play.training_game(rounds)\n",
    "    list_of_winners=[]\n",
    "    play.loadPolicy(policy_player1)\n",
    "    play.testing_game(rounds)\n",
    "    total_rounds+=rounds\n",
    "    print('agent wins', list_of_winners.count('agent')*100/rounds, 'percent of the test games, the Q-table has', len(play.states_value), 'entries after', total_rounds)\n",
    "end_time=time.time()\n",
    "print('it took', round(end_time-start_time,3), 'seconds to finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053dec3",
   "metadata": {},
   "source": [
    "### Below is the code for testing the changing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb177186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the agent wins 99.6 percent of the games\n"
     ]
    }
   ],
   "source": [
    "sequence_game=seq_game(14)\n",
    "list_of_winners=[]\n",
    "losing_games=[]\n",
    "sequence_game.change_strategy(1000)\n",
    "print('the agent wins', list_of_winners.count('agent')/len(list_of_winners)*100, 'percent of the games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad92523",
   "metadata": {},
   "source": [
    "### Below is the code for testing different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "423c567e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.656 0.01 0.1 0.1\n",
      "11.173 0.01 0.1 0.30000000000000004\n",
      "10.985 0.01 0.1 0.5\n",
      "4.98 0.01 0.1 0.7000000000000001\n",
      "12.027 0.01 0.1 0.9\n",
      "49.362 0.01 0.30000000000000004 0.1\n",
      "16.817 0.01 0.30000000000000004 0.30000000000000004\n",
      "5.409 0.01 0.30000000000000004 0.5\n",
      "4.384 0.01 0.30000000000000004 0.7000000000000001\n",
      "8.05 0.01 0.30000000000000004 0.9\n",
      "17.26 0.01 0.5 0.1\n",
      "6.479 0.01 0.5 0.30000000000000004\n",
      "6.88 0.01 0.5 0.5\n",
      "12.927 0.01 0.5 0.7000000000000001\n",
      "19.074 0.01 0.5 0.9\n",
      "108.717 0.01 0.7000000000000001 0.1\n",
      "11.085 0.01 0.7000000000000001 0.30000000000000004\n",
      "9.066 0.01 0.7000000000000001 0.5\n",
      "9.542 0.01 0.7000000000000001 0.7000000000000001\n",
      "4.725 0.01 0.7000000000000001 0.9\n",
      "108.665 0.01 0.9 0.1\n",
      "11.86 0.01 0.9 0.30000000000000004\n",
      "6.692 0.01 0.9 0.5\n",
      "3.273 0.01 0.9 0.7000000000000001\n",
      "4.411 0.01 0.9 0.9\n",
      "41.52 0.05 0.1 0.1\n",
      "2.074 0.05 0.1 0.30000000000000004\n",
      "2.904 0.05 0.1 0.5\n",
      "34.676 0.05 0.1 0.7000000000000001\n",
      "24.338 0.05 0.1 0.9\n",
      "12.844 0.05 0.30000000000000004 0.1\n",
      "3.52 0.05 0.30000000000000004 0.30000000000000004\n",
      "1.785 0.05 0.30000000000000004 0.5\n",
      "2.396 0.05 0.30000000000000004 0.7000000000000001\n",
      "6.141 0.05 0.30000000000000004 0.9\n",
      "7.681 0.05 0.5 0.1\n",
      "1.456 0.05 0.5 0.30000000000000004\n",
      "1.806 0.05 0.5 0.5\n",
      "1.816 0.05 0.5 0.7000000000000001\n",
      "63.447 0.05 0.5 0.9\n",
      "10.042 0.05 0.7000000000000001 0.1\n",
      "3.247 0.05 0.7000000000000001 0.30000000000000004\n",
      "1.509 0.05 0.7000000000000001 0.5\n",
      "3.53 0.05 0.7000000000000001 0.7000000000000001\n",
      "6.373 0.05 0.7000000000000001 0.9\n",
      "30.532 0.05 0.9 0.1\n",
      "2.194 0.05 0.9 0.30000000000000004\n",
      "2.853 0.05 0.9 0.5\n",
      "3.242 0.05 0.9 0.7000000000000001\n",
      "36.899 0.05 0.9 0.9\n",
      "9.498 0.09 0.1 0.1\n",
      "2.709 0.09 0.1 0.30000000000000004\n",
      "1.247 0.09 0.1 0.5\n",
      "7.82 0.09 0.1 0.7000000000000001\n",
      "3.866 0.09 0.1 0.9\n",
      "19.106 0.09 0.30000000000000004 0.1\n",
      "5.645 0.09 0.30000000000000004 0.30000000000000004\n",
      "1.246 0.09 0.30000000000000004 0.5\n",
      "17.126 0.09 0.30000000000000004 0.7000000000000001\n",
      "395.271 0.09 0.30000000000000004 0.9\n",
      "29.859 0.09 0.5 0.1\n",
      "1.728 0.09 0.5 0.30000000000000004\n",
      "0.713 0.09 0.5 0.5\n",
      "6.951 0.09 0.5 0.7000000000000001\n",
      "25.335 0.09 0.5 0.9\n",
      "12.935 0.09 0.7000000000000001 0.1\n",
      "2.49 0.09 0.7000000000000001 0.30000000000000004\n",
      "4.812 0.09 0.7000000000000001 0.5\n",
      "71.778 0.09 0.7000000000000001 0.7000000000000001\n",
      "60.323 0.09 0.7000000000000001 0.9\n",
      "2.561 0.09 0.9 0.1\n",
      "3.727 0.09 0.9 0.30000000000000004\n",
      "4.522 0.09 0.9 0.5\n",
      "9.805 0.09 0.9 0.7000000000000001\n",
      "10.644 0.09 0.9 0.9\n",
      "12.419 0.13 0.1 0.1\n",
      "2.982 0.13 0.1 0.30000000000000004\n",
      "14.868 0.13 0.1 0.5\n",
      "14.582 0.13 0.1 0.7000000000000001\n",
      "103.938 0.13 0.1 0.9\n",
      "22.095 0.13 0.30000000000000004 0.1\n",
      "5.855 0.13 0.30000000000000004 0.30000000000000004\n",
      "5.596 0.13 0.30000000000000004 0.5\n",
      "109.136 0.13 0.30000000000000004 0.7000000000000001\n",
      "114.724 0.13 0.30000000000000004 0.9\n",
      "11.563 0.13 0.5 0.1\n",
      "3.427 0.13 0.5 0.30000000000000004\n",
      "2.841 0.13 0.5 0.5\n",
      "11.653 0.13 0.5 0.7000000000000001\n",
      "11.762 0.13 0.5 0.9\n",
      "4.196 0.13 0.7000000000000001 0.1\n",
      "1.44 0.13 0.7000000000000001 0.30000000000000004\n",
      "3.981 0.13 0.7000000000000001 0.5\n",
      "119.556 0.13 0.7000000000000001 0.7000000000000001\n",
      "186.42 0.13 0.7000000000000001 0.9\n",
      "5.619 0.13 0.9 0.1\n",
      "4.338 0.13 0.9 0.30000000000000004\n",
      "7.711 0.13 0.9 0.5\n",
      "35.654 0.13 0.9 0.7000000000000001\n",
      "281.21 0.13 0.9 0.9\n",
      "5.047 0.17 0.1 0.1\n",
      "6.19 0.17 0.1 0.30000000000000004\n",
      "1.23 0.17 0.1 0.5\n",
      "19.069 0.17 0.1 0.7000000000000001\n",
      "300.008 0.17 0.1 0.9\n",
      "4.238 0.17 0.30000000000000004 0.1\n",
      "4.066 0.17 0.30000000000000004 0.30000000000000004\n",
      "21.385 0.17 0.30000000000000004 0.5\n",
      "177.287 0.17 0.30000000000000004 0.7000000000000001\n",
      "79.051 0.17 0.30000000000000004 0.9\n",
      "1.826 0.17 0.5 0.1\n",
      "5.17 0.17 0.5 0.30000000000000004\n",
      "45.797 0.17 0.5 0.5\n",
      "60.148 0.17 0.5 0.7000000000000001\n",
      "61.51 0.17 0.5 0.9\n",
      "6.939 0.17 0.7000000000000001 0.1\n",
      "4.884 0.17 0.7000000000000001 0.30000000000000004\n",
      "4.898 0.17 0.7000000000000001 0.5\n",
      "122.789 0.17 0.7000000000000001 0.7000000000000001\n",
      "43.752 0.17 0.7000000000000001 0.9\n",
      "3.981 0.17 0.9 0.1\n",
      "13.396 0.17 0.9 0.30000000000000004\n",
      "36.658 0.17 0.9 0.5\n",
      "34.662 0.17 0.9 0.7000000000000001\n",
      "166.966 0.17 0.9 0.9\n"
     ]
    }
   ],
   "source": [
    "list_of_alphas=[0.01*i for i in range(1,20,4)]\n",
    "list_of_gammas=[0.1*i for i in range(1,10,2)]\n",
    "list_of_epsilons=[0.1*i for i in range(1,10,2)]\n",
    "for alpha in list_of_alphas:\n",
    "    for gamma in list_of_gammas:\n",
    "        for epsilon in list_of_epsilons:\n",
    "            play = seq_game(n)\n",
    "            play.lr=alpha\n",
    "            play.decay_gamma=gamma\n",
    "            play.exp_rate=epsilon\n",
    "            rounds=1000\n",
    "            list_of_winners=[]\n",
    "            start_time=time.time()\n",
    "            while list_of_winners.count('agent')*100/rounds <100:\n",
    "                list_of_winners = []\n",
    "                play.training_game2(rounds)\n",
    "                #print('agent wins', list_of_winners.count('agent')*100/rounds, 'percent of the training games')\n",
    "                play.loadPolicy(policy_player1)\n",
    "                list_of_winners=[]\n",
    "                play.testing_game(rounds)\n",
    "                #print('agent wins', list_of_winners.count('agent')*100/rounds, 'percent of the test games')\n",
    "            end_time=time.time()\n",
    "            print(round(end_time-start_time,3), alpha, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7b4ca",
   "metadata": {},
   "source": [
    "1.23 0.17 0.1 0.5\n",
    "1.44 0.13 0.7000000000000001 0.30000000000000004\n",
    "0.713 0.09 0.5 0.5\n",
    "1.246 0.09 0.30000000000000004 0.5\n",
    "1.247 0.09 0.1 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
